{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60aa47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian personalized ranking\n",
    "# based on: http://ethen8181.github.io/machine-learning/recsys/4_bpr.html\n",
    "\n",
    "# loading packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "from itertools import product, islice\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from typing import Iterable, Any, Dict\n",
    "import pickle\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import rcParams\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7a19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 8, 4\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db4a41",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a66798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location for the datasets\n",
    "\n",
    "address2 = 'CSV/cdnelastic_VoD.csv'\n",
    "address = 'CSV/videos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1fc0325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the datasets\n",
    "\n",
    "# allcols = ['timestamp','statuscode','contentlength','host','timefirstbyte','timetoserv','hit','contenttype',\n",
    "#            'cachecontrol','cachename','popname','method','protocol','path','uid','sid','livechannel',\n",
    "#            'contentpackage','assetnumber','maxage','coordinates','devicebrand','devicefamily','devicemodel',\n",
    "#            'osfamily','uafamily','uamajor','manifest','fragment']\n",
    "# somecols = ['@timestamp','statuscode','contentlength','host','timetoserv','hit','contenttype',\n",
    "#               'protocol','uid','sid','livechannel','contentpackage','assetnumber','coordinates',\n",
    "#               'uafamily']\n",
    "# missing_values = ['n/a','na','--','NaN','NA','-']\n",
    "# # cdnset2 = pd.read_csv(address2,\n",
    "# #                      header=0,\n",
    "# #                      nrows=1000000,\n",
    "# #                      parse_dates=[0],\n",
    "# #                      comment='#',\n",
    "# #                      names=somecols,\n",
    "# #                      na_values=missing_values\n",
    "# #                     )\n",
    "# # print(cdnset2.info())\n",
    "# cdnset2 = pd.read_csv(address2,  na_values=missing_values)\n",
    "\n",
    "file_path = 'CSV/ml-100k/u.data'\n",
    "# we will not be using the timestamp column\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "cdnset2 = pd.read_csv(file_path, sep = '\\t', names = names)\n",
    "print('data dimension: \\n', cdnset2.shape)\n",
    "cdnset2.head()\n",
    "\n",
    "# cdnset2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24358db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset = cdnset2[['timestamp', 'uid', 'livechannel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdnset = cdnset2[['@timestamp', 'uid', 'contentpackage']]\n",
    "# cdnset = pd.read_csv(address,  na_values=missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4eff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afc95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_211/1231525476.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cdnset['@timestamp'] = pd.to_datetime(cdnset['@timestamp'])\n"
     ]
    }
   ],
   "source": [
    "cdnset['@timestamp'] = pd.to_datetime(cdnset['@timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9535ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16082173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eff417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing missing values for user id\n",
    "\n",
    "cdnset3 = cdnset.dropna(subset=['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2386a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdnset3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348429cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdn = cdnset3.groupby(['uid', 'contentpackage'], as_index=False).count()\n",
    "df_cdn = df_cdn.astype(int)\n",
    "# df_cdn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465e123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>contentpackage</th>\n",
       "      <th>requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>3528</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  contentpackage  requests\n",
       "0   24            3528        78\n",
       "1   59             918         1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "find a different way to engineer the ratings, not using frequencies.\n",
    "this is different with liveTV\n",
    "\n",
    "Engineer ratings in a binary way, e.g., yes/no, if requested then yes, otherwise no (binary rating)\n",
    "Research if it makes sense.\n",
    "\n",
    "!!! focus on this issue of sparsity\n",
    "\n",
    "The same user could have uniquely different ids across different hosts\n",
    "need to correspondence among\n",
    "Have to unify (across all hosts and all days) different attibutes of different ids(users, livechannels, etc.), across different hosts at least to curb the problem of sparsity\n",
    ".\n",
    "\n",
    "Looking at the data at the host level for different time windows, very low priority to uid\n",
    "Host based analytics with time. (host/time vs content)\n",
    "\n",
    "'''\n",
    "df_cdn.rename(columns={'@timestamp':'requests'}, inplace=True)\n",
    "df_cdn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5b760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16109, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37adefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique uid:  3670\n",
      "unique vod:  3422\n"
     ]
    }
   ],
   "source": [
    "print('unique uid: ',len(df_cdn.uid.unique()))\n",
    "print('unique vod: ',len(df_cdn.contentpackage.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa40ac-67c4-4288-af95-68565640e156",
   "metadata": {},
   "source": [
    "### Will start by constructing a user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20b853-eefa-4f9e-b39e-f838a9648a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the matrix\n",
    "\n",
    "# ratings1 = df_cdn.pivot(index='uid', columns='contentpackage').fillna(0, downcast='infer')\n",
    "# print(ratings1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990961dc-9adc-49fa-bffc-63bdfed3330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = np.array(ratings1)\n",
    "# print(ratings.shape)\n",
    "# print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4862b15-1d28-4f8b-8272-cc2c936446f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## better way to create the matrix\n",
    "\n",
    "def create_matrix(data, users_col, items_col, ratings_col, threshold=None):\n",
    "    '''\n",
    "    creating a user-item interaction matrix\n",
    "    '''\n",
    "    if threshold is not None:\n",
    "        data = data[data[ratings_col] >= threshold]\n",
    "        data[ratings_col] = 1\n",
    "        \n",
    "    for col in (items_col, users_col, ratings_col):\n",
    "        data[col] = data[col].astype('category')\n",
    "        \n",
    "    ratings = csr_matrix((data[ratings_col], (data[users_col].cat.codes, data[items_col].cat.codes)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf43d280-1f28-4e02-ab20-b5331f8883bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_211/2420268622.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[ratings_col] = 1\n",
      "/tmp/ipykernel_211/2420268622.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype('category')\n",
      "/tmp/ipykernel_211/2420268622.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype('category')\n",
      "/tmp/ipykernel_211/2420268622.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82520 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_col = 'item_id' # 'contentpackage'\n",
    "users_col = 'user_id' # 'uid'\n",
    "ratings_col = 'rating' # 'requests'\n",
    "threshold = 3\n",
    "# df = df_cdn\n",
    "\n",
    "X, df = create_matrix(cdnset2, users_col, items_col, ratings_col, threshold)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a678d-0700-4dc5-aa0b-1ae65f484f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot of users rating how many items\n",
    "# df_cdn.groupby('uid').count()['contentpackage']\n",
    "\n",
    "# shows at least one vod is rated by a particular user\n",
    "# thus for random split we will use this for testing algorithm\n",
    "\n",
    "# '''\n",
    "# number of users who requested how many movies.\n",
    "# '''\n",
    "\n",
    "# plt.hist(np.sum(ratings != 0, axis = 1), range=[0, 30],histtype = 'stepfilled', bins = 90, label = '# of ratings')\n",
    "# plt.axvline(x = 1, color = 'black', linestyle = '--')\n",
    "# plt.legend(loc = \"upper right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f488c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking for non-zero elements in the matrix\n",
    "# if dataset too sparse (sparsity below 1%)\n",
    "\n",
    "# matrix_size = np.prod(ratings.shape)\n",
    "# interaction = np.flatnonzero(ratings).shape[0]\n",
    "# sparsity = 100 * (interaction / matrix_size)\n",
    "\n",
    "# print('dimension: ', ratings.shape)\n",
    "# print('sparsity: {:.1f}%'.format(sparsity))\n",
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd6da6db-4e94-432c-aced-01e42135afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly splitting the dataset into train and test sets\n",
    "\n",
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    \n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "    \n",
    "    \n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "    \n",
    "    # randomly chosen interactions\n",
    "    # masking interactions in training and assigning them to the test set\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "        \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77e03833-9459-4030-9c00-86e9c252874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.2, seed = 1234)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e16d7a1e-0e7c-44c1-871c-1a69f10e5dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16879 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f67fb",
   "metadata": {},
   "source": [
    "## BPR Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9115642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating the matrix factorization (MF) class for modeling purpose\n",
    "\n",
    "class BPRMFClass:\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate (alpha) : float, default 0.01\n",
    "        learning rate for gradient descent\n",
    "\n",
    "    n_factors (hidden) : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    n_iters : int, default 15\n",
    "        Number of iterations to train the algorithm\n",
    "        \n",
    "    batch_size : int, default 1000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg (beta) : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d ndarray, shape [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d ndarray, shape [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme \n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha = 0.01, hidden = 15, n_iters = 10, batch_size = 1000, reg = 0.01, seed = 1234, verbose = True):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.hidden = hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "        \n",
    "    def fit(self, ratings):\n",
    "        '''\n",
    "        ratings: scipy sparse csr_matrix; user-item interactions\n",
    "        '''\n",
    "        indptr = ratings.indptr\n",
    "        indices = ratings.indices\n",
    "        n_users, n_items = ratings.shape\n",
    "        \n",
    "        # ensure batch size to be smaller than total number of users to\n",
    "        # avoid sampling with replacement\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write('size greater than user count, update batch size of {}\\n'.format(n_users))\n",
    "            \n",
    "        batch_iters = n_users // batch_size\n",
    "        \n",
    "        #initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.hidden))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.hidden))\n",
    "        \n",
    "        # tracking progress with verbose, if it is on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "            \n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                sampled = self._sample(n_users, n_items, indices, indptr)\n",
    "                #print('sampled:',sampled)\n",
    "                sampled_users, sampled_pos_items, sampled_neg_items = sampled\n",
    "                self._update(sampled_users, sampled_pos_items, sampled_neg_items)\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def _sample(self, n_users, n_items, indices, indptr):\n",
    "        '''sample batches of random triplets u, i, j'''\n",
    "        sampled_pos_items = np.zeros(self.batch_size, dtype = int)\n",
    "        sampled_neg_items = np.zeros(self.batch_size, dtype = int)\n",
    "        sampled_users = np.random.choice(n_users, size = self.batch_size, replace = False)\n",
    "        #print('sampled users:',sampled_users)\n",
    "        \n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[indptr[user]:indptr[user + 1]]\n",
    "            #print('positive itemsss:',pos_items)\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            #print('positive item:',pos_item)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            #print('negative item:',neg_item)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "                \n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "            \n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items\n",
    "    \n",
    "    def _update(self, u, i, j):\n",
    "        '''\n",
    "        updating according to bootstrapped user u, positive item i and\n",
    "        negative item j\n",
    "        '''\n",
    "        user_u = self.user_factors[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "        \n",
    "        # compute difference between the score of positive items and negative items\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis = 1)\n",
    "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid hidden_factors times so that\n",
    "        # dimensions will match when doing the update\n",
    "        sigmoid_tiled = np.tile(sigmoid, (self.hidden, 1)).T\n",
    "        \n",
    "        # update using gradient descent (optimization)\n",
    "        grad_u = sigmoid_tiled * (item_j - item_i) + self.reg * user_u\n",
    "        grad_i = sigmoid_tiled * -user_u + self.reg * item_i\n",
    "        grad_j = sigmoid_tiled * user_u + self.reg * item_j\n",
    "        self.user_factors[u] -= self.alpha * grad_u\n",
    "        self.item_factors[i] -= self.alpha * grad_i\n",
    "        self.item_factors[j] -= self.alpha * grad_j\n",
    "        return self\n",
    "    \n",
    "    def predict(self):\n",
    "        '''\n",
    "        predicted ratings for every user and items\n",
    "        '''\n",
    "        if self._prediction is None:\n",
    "            self._prediction = self.user_factors.dot(self.item_factors.T)\n",
    "            \n",
    "        return self._prediction\n",
    "    \n",
    "    def _predict_user(self, user):\n",
    "        '''return predicted ratings for specified user,\n",
    "        mainly used in computing evaluation metric\n",
    "        '''\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred\n",
    "    \n",
    "    def recommend(self, ratings, N = 5):\n",
    "        '''\n",
    "        return top N ranked items for given user id\n",
    "        '''\n",
    "        n_users = ratings.shape[0]\n",
    "        recommendation = np.zeros((n_users, N), dtype = np.uint32)\n",
    "        for user in range(n_users):\n",
    "            top_n = self._recommend_user(ratings, user, N)\n",
    "            recommendation[user] = top_n\n",
    "            \n",
    "        return recommendation\n",
    "    \n",
    "    def _recommend_user(self, ratings, user, N):\n",
    "        '''top-N ranked items for given user'''\n",
    "        scores = self._predict_user(user)\n",
    "        \n",
    "        # computing top N items, excluding those a user already liked\n",
    "        liked = set(ratings[user].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "            \n",
    "        top_n = list(islice((rec for rec in best if rec not in liked), N))\n",
    "        return top_n\n",
    "    \n",
    "    def get_similar_items(self, N = 5, item_ids = None):\n",
    "        '''\n",
    "        return top N similar items for particular item id, cosine distance\n",
    "        is used as distance metric\n",
    "        '''\n",
    "        # cosine distance is proportional to normalized euclidean distance\n",
    "        normed_factors = normalize(self.item_factors)\n",
    "        knn = NearestNeighbors(n_neighbors = N + 1, metric = 'euclidean')\n",
    "        knn.fit(normed_factors)\n",
    "        \n",
    "        # returns a distance, index tuple\n",
    "        if item_ids is not None:\n",
    "            normed_factors = normed_factors[item_ids]\n",
    "            \n",
    "        _, items = knn.kneighbors(normed_factors)\n",
    "        similar_items = items[:, 1:].astype(np.uint32)\n",
    "        return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0921dfc4-27ed-4f98-bfdd-c7186aea28df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPRMFClass: 100%|██████████| 160/160 [00:03<00:00, 45.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BPRMFClass at 0x7f58e244f7c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing random parameters to test the class\n",
    "bpr_params = {'reg': 0.01,\n",
    "              'alpha': 0.1,\n",
    "              'n_iters': 160,\n",
    "              'hidden': 15,\n",
    "              'batch_size': 100,\n",
    "              #'seed' : 1, \n",
    "              #'verbose' : True\n",
    "             }\n",
    "\n",
    "# training a model\n",
    "bprmodel = BPRMFClass(**bpr_params)\n",
    "bprmodel.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b030f7a-ffd7-43b0-82fd-dd6f48f5db30",
   "metadata": {},
   "source": [
    "### performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3730fe94-aa31-4867-9a43-1d84e6566919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the ROC-AUC score to evaluate performance of the model between 0.0 and 1.0\n",
    "def auc_score(model, ratings):\n",
    "    '''\n",
    "    computing area under the ROC curve:\n",
    "    as it computes the auc for every user's prediction and actual interaction\n",
    "    \n",
    "    '''\n",
    "    auc = 0.0\n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "    auc /= n_users\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "074045d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956550383931248\n",
      "0.8272192019285816\n"
     ]
    }
   ],
   "source": [
    "# performance scores for training and testing\n",
    "print(auc_score(bprmodel, X_train))\n",
    "print(auc_score(bprmodel, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299e4d5-1fd6-4a95-92a3-2783a52d56a4",
   "metadata": {},
   "source": [
    "### recommending items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1782bd0e-f2eb-4425-8f67-0f99a26387f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 256,   49,  274,  236,   99],\n",
       "       [ 453,    2, 1515, 1483,   54],\n",
       "       [   1, 1515,  208,  209,  467],\n",
       "       ...,\n",
       "       [ 350, 1429,  957,  779, 1448],\n",
       "       [1486,  415, 1443, 1098, 1479],\n",
       "       [ 809,  750,  697, 1084, 1353]], dtype=uint32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting similar items: top N\n",
    "bprmodel.get_similar_items(N = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03b5b766-ae35-4dd7-9ec1-c50e311fdc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11, 425, 316, 193, 473],\n",
       "       [806, 293, 123,   8, 741],\n",
       "       [301, 744, 743, 683, 312],\n",
       "       ...,\n",
       "       [285, 267, 312,  99, 124],\n",
       "       [301,  11, 180, 172, 744],\n",
       "       [ 88, 190,  81, 264, 143]], dtype=uint32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting top N recommended items\n",
    "bprmodel.recommend(X_train, N = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c9987-10d1-4916-9554-1470f3fae25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755a8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd863c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9154f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723922c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb689119",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8572501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2394c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle/joblib the trained model\n",
    "\n",
    "# with open('BPRMF_model','wb') as f:\n",
    "#     pickle.dump(bprmodel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and make predictions\n",
    "\n",
    "# with open('BPRMF_model','rb') as fr:\n",
    "#     model = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = model.predict()\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef86f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fda726f9",
   "metadata": {},
   "source": [
    "# Log Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bae57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdn_frequency['log_freq']=np.log10(df_cdn_frequency.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdn_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdn_frequency['log_rating']=np.rint(df_cdn_frequency.log_freq).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdn_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32f5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff36c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
